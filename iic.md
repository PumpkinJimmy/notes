## Invarient Information Clustering CNN
（自己搞得）中文译名：信息不变性聚类网络
### 前置知识
- 相对熵（KL散度）：两个分布之间的差距
- 互信息：联合分布$p(x,y)$和边缘分布的乘积$p(x)p(y)$的相对熵（KL散度），表明的是某一随机变量蕴含的关于另一个随机变量的信息量
### 综述
- 无监督图像分类网络
- 区别于传统的聚类算法，采用深度学习+互信息得到不易退化的鲁棒的模型
### 原理
- 最终目标：$X \to Y$的映射,其中$X$是输入，$Y \in \{0, 1\}^C$
- 实际目标：目标为条件分布$P_{c|x}$（参见softmax）
- 算法思路：从$x$构造成对的输入$x, x'$，构造方法可以是随机的对称、反转、切取等，构造网络$\Phi:x \to y, y \in [0,1]^c$，得到优化目标：
  $$
      max_{\Phi}I(\Phi(x);\Phi(x'))
  $$
- 优化目标的定性解释是：由于$x,x'$来自同一类，我们希望它们对应$y$的能给出更大的互信息从而强化它们的关联，达到“同一类图片的输入得到同一个类别输出”的聚类的目的

### 为什么IIC能防止退化的聚类方案
互信息的表达式：
$$
  I(\Phi(x), \Phi(x')) = I(z, z') = H(z) - H(z|z')
$$
最大化互信息意味着需要在最大化$H(z)$和最小化$H(z|z')$之中权衡

当$H(z|z')$取最小时，$z$可以完全由$z'$预测出来，一般这是我们想要的，但显然当$\Phi(x)$为一常函数时同样符合要求，这是退化的聚类方案（全部聚到同一类）；

当$H(z)$取最大时，归到每一类的概率是完全均匀的。一般这是退化的聚类方案（完全不聚类），但综合对$H(z|z')$的要求，我们可以得到折中的非退化聚类方案

### 正确食用IIC论文的代码
- 由于原代码基于过时的Python27和PyTorch0.4编写，需要手动适配Python3
- 使用适当的Net类，再相应使用合适的参数load_state_dict（无需适配）以及适当的config（需要适配）
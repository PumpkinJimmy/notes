## Operating System
### x86计算机启动流程

x86计算机启动流程：

1. 上电，BIOS，
   
   处理器上电后**立刻执行烧写在某ROM芯片中的BIOS程序**。BIOS程序进行上电自检、初始化最基本的硬件设备并**载入并执行启动盘的起始512字节代码**。

   说明：
   1. BIOS是固件的一种，是硬件出厂的时候写在ROM里的一小段程序，CPU被设计为上电就会自动执行这段程序。这段程序会初始化最基本的硬件设备，包括启动盘、内存、显示器、键盘（甚至鼠标）
   2. 启动盘的起始512字节可执行代码是无操作系统平台约束的x86裸代码，称为**bootloader**
   3. BIOS是统称，实际上现在采用的BIOS是UEFI

2. Bootloader

   启动盘起始512字节负责将完整的引导启动程序载入内存并**引导启动操作系统**
   
   说明：
   
   bootloader而在Windows平台下又称为MBR（主引导记录）。这是因为实际上512字节往往不足以完成全部载入工作，故这512字节做的事其实是把完整的引导启动程序载入到内存并执行。

    bootloader承担着如下任务：
    - **载入操作系统内核**：在启动盘中定位内核位置并载入到内存中
    - **切换至32位/64位保护模式**：x86 CPU启动的初始状态是**16位实模式**。该模式下程序直接访问物理内存，没有进程、多任务，但只能寻址1MB的内存空间。需要bootloader将CPU切换至保护模式，从而支持现代计算机的众多特性（段页式虚拟内存管理，进程管理等）
    - 将某些BIOS得到的硬件信息转交给OS

    实际上Linux的多系统引导程序Grub也就是一个bootloader，但Grub较为复杂，可以引导不同的操作系统的启动


### 自学笔记：中断

现代CPU允许外部设备以某种方式触发*中断*来使CPU暂停当前指令的执行、保存上下文并切换PC指针至特定的位置。通常中断后CPU会切换至*中断处理程序*处继续执行命令，并通常在中断处理程序完成后通过恢复保存的上下文来返回中断的点继续执行。

“中断”二字具有误导性，除了异常中断，通常“中断”其实是指*暂停*当前的控制流并执行中断处理程序，最后恢复到原来的控制流。

中断机制的作用在于**避免轮询，通过异步提高处理器利用率**。

具体来说，假设没有中断机制，再CPU执行到IO相关指令后，需要发送信号到IO模块，并反复检查IO模块的状态寄存器（也即*轮询*）以确定IO模块是否完成了工作，并在IO模块完成工作后开始读/写IO模块缓冲区的数据，再继续执行。这一轮询过程中CPU是始终在没有意义地忙的，因为轮询的实质是“等待完成”，表现在程序执行上就是*阻塞*。偏偏IO设备的速度往往远低于CPU，故轮询会造成巨大的CPU资源浪费。

例如：

> 常见家用机械硬盘是7200转/s的，故磁碟旋转半周需要4ms，耗时约400万CPU周期，若不使用中断，读取硬盘数据的过程中，CPU不得不等待机械硬盘寻道读取数据再写入到缓冲区，CPU才能读取，这是巨大的浪费。

中断机制允许采用如下机制：CPU向硬盘控制器发出读信号后，不作轮询，继续执行接下来的程序。硬盘控制器在完成读盘后，触发CPU中断，CPU暂停当前指令流，执行中断处理程序读入硬盘缓冲区里的数据，最后恢复指令流继续执行。

一个合适的类比是**回调**。中断机制可以看作允许CPU为IO操作注册“回调”。（实质上回调机制最有效的应用场景之一正是基于硬件中断的IO复用）

常见的中断类型：
- 程序中断：也称“异常”，即程序执行了不合法的操作
- 硬件故障中断
- **IO中断**：由IO控制器产生，用以通知CPU完成了某IO操作。举例：磁盘读写，网络通信，打印
- **时钟中断**：CPU内部计时器产生，用来实现“定时类”功能。

中断机制的一个很好的案例是Nginx的异步IO复用。（待完善）

### Process
- Process Image = Code Segment + Data Segment + Stack Segment + Process Control Block(PCB)
- PCB
  - pid（可能还有ppid,uid）
  - state: running/ready/blocked
  - priority
  - Program Counter (PC)
  - memory pointers: 内存相关指针
  - context: registers
  - IO information: such as file descriptors
  - accounting information: 进程相关统计信息
  - 注意，PCB中memorgy pointers + context + IO info.对应管理的资源可以看作一台逻辑上完整的计算机的全部资源。这暗示了进程运行相互独立相互隔离的特点
- 进程状态模型
  - 二状态模型
    - 最基本的模型，进程分别为运行态和等待态
    - 过于简单
  - 五状态模型
    - 进程分为*运行态*、*就绪态*和*阻塞态*，以及方便管理的起始态和结束态
    - *运行态*表示进程正在运行
    - *就绪态*表示进程不在运行，但请求的资源都已就绪，只等调度器调入运行
    - *阻塞态*表示进程正在等待IO/其他资源，从而阻塞
  - 六状态模型/七状态模型
    - 结合虚拟存储器，可以在无状态模型上添加*挂起态*
    - 挂起态的进程不在运行，且进程映像被调出主存，存在辅存中
    - 设计挂起态的动机是解决主存容量不足，将长久不运行的进程移出主存，在需要的时候才调入
    - 不正确地使用挂起态可能会导致性能下降（缺页的时间代价很大）
    - 由于虚拟存储器地分页机制，不一定要把整个进程映像挪到辅存中，可以把一部分（部分页）放在辅存中
- 进程控制原语
  - 依赖OS的*原语*来实现进程的分发、状态切换等操作
  - 原语与常规程序偏度不同，原语是*原子操作*，不可以中断，否则会导致混乱
  - 一个常见的手法是通过不响应中断来实现原子性
  - 逻辑上来看，OS原语可以看作对ISA的扩充，增加了指令

### Process vs. Thread
- 进程是**资源分配的最小单位**
  - OS为进程分配pid、内存、fd表等资源，*不单独为线程分配这些资源*
  - 具有独立的PCB、特权级等
  - 进程可以是OS层面并发执行的较粗粒度。
- 线程是**调度执行的最小单位**
  - OS可以以线程为单位分配CPU时间。
  - 线程是OS层面并发执行的最小粒度。
  - 同一进程派生的多个线程**共享资源**，比如fd，内存地址空间等

### 用户级线程 vs. 内核级线程

用户级线程（ULT）
- 在用户级代码实现多线程
- 代表性的库是pthread
- 优点：
  - 不需要切换至内核态
  - 调度策略可以由应用程序定制
  - 可以跨平台
- 缺点：
  - 由于发起系统调用时进程被阻塞，只要有一个线程发起系统调用时，同一进程的所有派生的用户级线程都会阻塞
  - 在纯粹的用户级线程策略中，用户级线程无法利用多核
- 当然现在的ULT解决了部分缺点，比如说非阻塞的系统调用
  
系统级线程（KLT）
- 线程管理由内核完成，OS的调度以线程为单位
- 优点：
  - 线程阻塞不会导致进程阻塞
  - 充分发挥多核优势
- 缺点：
  - 线程调度切换需要内核介入，故有模式切换开销

还有混合ULT和KLT的方案（比如Solaris），在线程创建在用户态，线程调度和同步在内核态，此时ULT被映射到了若干个KLT

### 对称多处理SMP：同构

SMP 对称多处理是指**有多个具有相同功能的逻辑上的处理器**， 也即*同构*多处理器技术（区别异构）

多核处理器是SMP的一种实现，又称为*片上SMP*

### Windows进程模型

Windows系统思想：**一切皆资源/一切皆对象**。所有的资源都表示为对象(object)，然后使用句柄(handle)来管理。进程是占用资源的基本单位，一个进程的句柄表包含该进程拥有的资源，比如打开的文件、代码段、数据段，和*线程对象*。（由此可见，Windows下进程和线程是截然不同的逻辑实体）

Windows对象具有*属性*和*服务*（方法），许多时候，Windows的进程/线程属性对标的就是进程模型的PCB/TCB

### Linux进程模型
Linux的设计思想：**一切皆文件**。因此Linux进程占有的资源主要表现为其“打开”的文件，或者说其*文件描述符表*

Linux实际上没有区分进程和线程

### Mac/iOS的GCD技术
Mac/iOS处理基本的内核即线程实现之外，还在OS中提供了更强大的自动线程管理功能。用户不需要显式使用OS API，而是使用拓展的C语言记号来标识需要并发的“块”，然后由OS来创建线程、管理线程，根据底层硬件的特性来调整策略。

### 互斥：六个要求
- **强制排他**：这是最基本的要求。同一时刻只有一个进程进入临界区
- **让权等待**：当进程无法进入临界区时立刻释放处理器，防止**忙等待**（浪费CPU时间）
- **有限等待**：一个试图进入临界区的进程不会无限地等待，也即不会*饥饿*
- **充分并发**：各个进程可以互不干扰地并发运行
- 满足异步：各个进程并发逻辑不受处理器数量和相对速度影响
- 空闲让进：当没有代码试图进入临界区时，一个进入临界区的尝试可以立刻成功


### 互斥：软件实现：Dekker算法
考虑多线程互斥，使用全局变量flag来表示n个竞争进入临界区的线程。使用turn表示“是否谦让”。大致流程如下：
1. `flag[id]`标为true
2. 轮询其他所有flag
3. 若互斥，等待，若谦让，在短暂`flag[id]=false`后重新使`flag[id]=true`
4. 进入临界区
5. `flag[id]`标为false

问题：
- 逻辑复杂，难以证明
- 轮流问题（谦让度顺序变化）
- **忙等待**

### 互斥：软件实现：Peterson算法

考虑多线程互斥，大致流程
1. `flag[id]=1`
2. `turn=other's id`
3. 轮询其他所有flag，检查turn，只要当有其他人flag为真且turn不等于自己时就等待
4. 进入临界区
5. `flag[id]=0`

特点：
- 较容易实现
- 无轮流
- **忙等待**

### 互斥：硬件实现

简单粗暴：关中断
- 在进程进入临界区的时候关中断（不响应中断）
- 缺点1：限制了处理器交替执行的能力
- 缺点2：对多核情形不生效（单核情形下一切切换源自中断，但多核情形下具有天然的并行）

完整实现：**TS/XCHG&自旋锁**

- 观察软件方案，可以发现软件方案失败的根本原因是**轮询操作中“test”和“set”操作中间可能被切换**。因此可以在硬件上设计一个“TestSet”指令在一个指令周期内完成两个操作
- 此方案适用如下情形：
  
  互斥的存储器 & 共享存储的SMP

- TestSet实现自旋锁
  考虑如下自旋锁的（伪）汇编代码：
  ```asm
  lockvar db 0

  proc lock(lockvar)
    loop:
      TS lockvar
      jnz loop
    ret
  endproc

  proc unlock(lockvar)
    loop:
      mov lockvar, 0
    ret
  endproc
  ```

  代码说明：

  加锁逻辑：lockvar为0时没有进程在临界区中，1则表示有进程在临界区中。测试lockvar的值并将lockvar置1，若lockvar的原来的值是0，则成功获得锁，允许进入临界区；否则，获得锁失败，循环等待，直到lockvar为0。

  关键点：
  - 硬件实现了一个TS指令，**在一个指令周期**内完成“检查lockvar的值”和“lockvar置1”的动作。由于在一个指令周期内，**两个动作是不会被中断**，且由于存储器的“互斥”，**多个处理器同时加锁也只有一个进程获得锁**
  - 无论测试结果如何，都要置1的理由是：若加锁失败，lockvar肯定本来就是1，不受影响；若加锁成功，为了排除其他进程，也必须立即将lockvar设为1
  
- XCHG实现自旋锁
  
  XCHG可以在一个指令周期内**交换一个寄存器和一个内存单元的数据**

  ```asm
  lockvar db 0

  proc lock(lockvar)
    loop: 
      mov ax, 1
      XCHG ax, lockvar
      jnz loop
    ret
  endproc

  proc unlock(lockvar)
    mov ax, 0
    ret
  endproc
  ```

  可以看到，XCHG和TS指令工作的实质是一样的：在一个指令周期内同时获知一个内存单元的值并设置该内存单元的值。XCHG将内存单元的值和寄存器的值对调，然后测试寄存器的值即可知道内存单元原来的值。

- 自旋锁 vs 互斥锁
  - 互斥锁是*sleep-waiting*（让权等待），等待锁的进程会阻塞，在解锁之前阻塞不会获得CPU时间
  - 自旋锁是*busy-waiting*（忙等待），等待锁的进程不会阻塞，而是不断轮询（不断循环）。由于没有阻塞，该进程会占用CPU时间
  - 自旋锁：
    - 由于不阻塞，如果等待时间很短，性能会远胜于互斥锁
    - 易于实现
    - 如果等待时间很长，由于忙等待，将浪费CPU时间
    - 可能饥饿
    - 可能死锁
  - 互斥锁：
    - 由于等待的时候阻塞，然后又唤醒调入，开销较大
    - 但由于等待的时候阻塞（让权等待），不会浪费CPU时间
    - 由于可以由OS调度，可以减少饥饿的问题
    - 可能死锁

### 信号量

信号量其实就是就是进程间通信用的一个共享的整数变量。

一个信号量只有三种合法操作

1. 初始化
   
   初始化信号量为一个非负整数。具体取值取决于使用信号量的具体情景。

2. P操作（Wait/Down）
   
   信号量减1。若信号量此时**为负**，**执行P操作的进程阻塞**
  
3. V操作（Signal/Up）
   
   信号量加1。若信号量此时**非正**，**唤醒其中一个因P操作阻塞的进程**。

注意，每一个信号量对应一个阻塞队列，其中放置了由于对该信号量的P操作阻塞的所有进程。

信号量除了是一个整数，还需要对应一个*阻塞队列*，存放**因对该信号量做P操作而阻塞的进程控制块**

一种取值只能是0或者1的特殊的信号量，称为*二元信号量*。由于此时这种信号量不存在负数的情形，因此二元信号量不是根据信号量取值来判断是否阻塞的，而是检测*阻塞队列是否为空*。因此，所谓二元信号量其实跟那个整数没什么关系。

#### 信号量实现

可以发现，对同一个信号量的P操作V操作是典型的可能导致竞态的操作。因此，P/V操作必须利用自旋锁来确保互斥修改（不要试图用互斥锁，因为互斥锁本事就是用信号量实现的。。。）


#### 信号量实现互斥锁

显然，如果信号量初始为1，该信号量其实就是sleep-waiting的**互斥锁**（由于是sleep-waiting，所以不是自旋锁）

几个要点：
1. 配置一个**初始为1**的信号量（常常被称为*互斥量*）
2. 试图进入临界区的进程需要对信号量执行P操作（即*lock*）
3. 离开临界区时，进程对信号量执行V操作（即*unlock*）

#### 生产者-消费者问题

问题描述：

若干个进程通过有限的共享缓冲区交换数据
- 一组“生产者”进程不断写入
- 另一组“消费者”进程不断读出
- **任何时刻只能有一个进程可以对缓冲区进行操作**

解决方案：**使用信号量实现的队列**。
- 使用一个信号量用于同步。
- 生产者每次将产品入队都会导致信号量+1；
- 当队列为空的时候，试图获取产品的消费者将会导致信号量为负，从而导致消费者阻塞等待；
- 生产者一放入新产品，就会导致信号量+1，若信号量为负，等待的某个消费者进程立即被唤醒，并得到新入队的产品，继续执行。
- *若缓冲区有限，则在缓冲区满的情况下，生产者可能需要阻塞等待。此时可能需要增加一个信号量。
- 最后，由于涉及共享变量的修改，所以还需要一个互斥锁

#### 读者-写者问题

问题描述：对于同一组数据资源（比如文件），要求满足以下要求：
- 任意多个读进程可以同时读文件
- 一次只能有一个写进程写文件
- 如果一个写进程在写文件，任意读进程都不能读文件

这种问题的典型情境是*数据库的读写*。数据库90%的请求都是读，数据库需要满足大量并发的读请求，因此要允许大量进程同时读；但又需要维护数据一致性，因此必须在写的时候锁定数据表。

容易既有读者在排队，又有写者在排队，因此有两种策略：
1. 读者优先：当读者持有锁的时候，任何新的读者都可以立刻进入使用资源
2. 写者优先：当读者持有锁，写者在等待时，新来的读者不能立刻进入使用资源，而是现有读者使用完之后立刻将资源交给写者。

读者有限的解决方案如下：
1. 初始化信号量`r=1,w=1`
2. 读者逻辑：
   
   1. `p(r)`
   2. 当前读者数+1
   3. 若当前读者数=1，则`p(w)`
   4. `v(r)`
   5. `READ`操作
   6. `p(r)`
   7. 当前读者数-1
   8. 若当前读者数=0，则`v(w)`
   9. `v(r)`

3. 写者逻辑：

   1. `p(w)`
   2. `WRITE`操作
   3. `v(w)`

注：
- 写者逻辑非常简单：每次写数据之前`lock(w)`，写完`unlock(w)`
- 读者需要使用两个锁：
  - 当前读者数量是所有读者线程共享的变量，修改时都要`lock(r)`
  - 若一个新的读者获得读锁，发现`reader_count==1`，说明**在它之前，读者并未对资源加锁**，此时必须执行`lock(w)`来保证不会既读又写。
  - 若一个新读者获得读锁，发现`reader_count>1`，说明**在它之前，读者已经为资源加锁了，其他读者可以自由进入资源临界区读数据**
  - 无论何种情况，一个新读者完成`lock(r)`并互斥地为读者数量+1之后，可以`unlock(r)`了
  - 类似的，当读取完成，`reader_count--`时，若`reader_count==0`，就要`unlock(w)`了
- **读者优先可能导致写者饥饿**。由于当读者持有锁的时候，任何新的读者都可以立刻进入使用资源，也即若不断有新的读者进入，写者永远无法进入临界区。因此实际操作中写者优先相对读者优先实用。

写者优先的解决方案如下：

```
writer:
  p(y)
  write_count++
  if (write_count==1) p(rsem) 
  v(y)

  p(wsem)
  WRITE_UNIT()
  v(wsem)

  p(y)
  write_count--
  if (write_count==0) v(rsem)
  v(y)
```

```
reader:
  p(z)
  p(rsem)

  p(x)
  read_count++
  if (read_count==1) p(wsem)
  v(x)

  v(z)
  READ_UNIT()

  p(x)
  read_count--
  if (read_count==0) v(wsem)
  v(x)
```

#### 进程同步

互斥可以*强制排他*，结果上来说可以实现**临界区访问的顺序化**（无重叠），但它无法保证多个协作进程的**时序**。并发进程之间的时序约束问题称为*进程同步*问题。

#### 信号量实现进程同步

考虑`a -> b`的一个同步要求，采用一个信号量实现`s`

要点如下：
1. 初始化`s=0`
2. a完成后执行`v(s)`操作
3. b开始前执行`p(s)`操作（即*join*）

### 消息机制

一种相对高层的IPC机制

两种原语：

- `send` 发送消息
- `receive` 接收消息
  
其中`send/receive`都可以是阻塞/非阻塞的

消息传递既可以是直接发送给给定PID的进程，也可以是使用中间代理结构（信箱）来通信

作为一种高级的IPC方式，消息机制完全可以用于*分布式系统*。

实现消息机制最重要的部件是*消息队列*

### 死锁

死锁发生的四个必要条件

1. 互斥
   
   进程可以排他地占有资源

2. 占有等待
   
   进程在由于请求其他资源阻塞等待的时候仍然占有着属于自己的资源

3. 不可抢占
   
   不允许一个进程*抢占*另一个进程的资源。

   *抢占*是指某资源在其持有的进程使用完并主动释放之前被另一个资源强占。

作为前三个条件的结果，条件四：

4. 循环等待
   


总体上，三种解决死锁的策略：

1. 死锁预防
   
   保守的策略，通过**破坏死锁发生的必要条件**来完全杜绝死锁的发生。

2. 死锁避免

   类似死锁预防

3. 死锁检测
   
   在运行时由OS定期扫描检测死锁

#### 死锁预防

1. 破坏互斥：不可能
   
   互斥是并发程序避免RC保持数据一致性的基础，不可能通过这一方法来避免死锁。

2. 破坏占有等待：**初始一次性申请所有资源**
   
   若要求进程在创建之时申请所有需要的资源，得到资源之后才允许启动，**不允许进程在执行过程中申请新的资源，则可以避免占有着资源进行阻塞等待**。

   优点：易于实现、易于理解

   缺点：
   - 资源利用率低：进程在运行的整个生命周期中占有着所有涉及到的资源，但该资源可能只是在进程执行的一小部分使用到了该资源，剩余时间资源都空置浪费了。

3. 抢占
   
4. 破坏循环等待：按序分配
   
   含义：进程A若想申请资源$R_j$，必须保证$\forall i < j$，资源$R_i$已被分配

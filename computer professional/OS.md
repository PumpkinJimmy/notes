## Operating System
### x86计算机启动流程

x86计算机启动流程：

1. 上电，BIOS，
   
   处理器上电后**立刻执行烧写在某ROM芯片中的BIOS程序**。BIOS程序进行上电自检、初始化最基本的硬件设备并**载入并执行启动盘的起始512字节代码**。

   说明：
   1. BIOS是固件的一种，是硬件出厂的时候写在ROM里的一小段程序，CPU被设计为上电就会自动执行这段程序。这段程序会初始化最基本的硬件设备，包括启动盘、内存、显示器、键盘（甚至鼠标）
   2. 启动盘的起始512字节可执行代码是无操作系统平台约束的x86裸代码，称为**bootloader**
   3. BIOS是统称，实际上现在采用的BIOS是UEFI

2. Bootloader

   启动盘起始512字节负责将完整的引导启动程序载入内存并**引导启动操作系统**
   
   说明：
   
   bootloader而在Windows平台下又称为MBR（主引导记录）。这是因为实际上512字节往往不足以完成全部载入工作，故这512字节做的事其实是把完整的引导启动程序载入到内存并执行。

    bootloader承担着如下任务：
    - **载入操作系统内核**：在启动盘中定位内核位置并载入到内存中
    - **切换至32位/64位保护模式**：x86 CPU启动的初始状态是**16位实模式**。该模式下程序直接访问物理内存，没有进程、多任务，但只能寻址1MB的内存空间。需要bootloader将CPU切换至保护模式，从而支持现代计算机的众多特性（段页式虚拟内存管理，进程管理等）
    - 将某些BIOS得到的硬件信息转交给OS

    实际上Linux的多系统引导程序Grub也就是一个bootloader，但Grub较为复杂，可以引导不同的操作系统的启动


### 自学笔记：中断

现代CPU允许外部设备以某种方式触发*中断*来使CPU暂停当前指令的执行、保存上下文并切换PC指针至特定的位置。通常中断后CPU会切换至*中断处理程序*处继续执行命令，并通常在中断处理程序完成后通过恢复保存的上下文来返回中断的点继续执行。

“中断”二字具有误导性，除了异常中断，通常“中断”其实是指*暂停*当前的控制流并执行中断处理程序，最后恢复到原来的控制流。

中断机制的作用在于**避免轮询，通过异步提高处理器利用率**。

具体来说，假设没有中断机制，再CPU执行到IO相关指令后，需要发送信号到IO模块，并反复检查IO模块的状态寄存器（也即*轮询*）以确定IO模块是否完成了工作，并在IO模块完成工作后开始读/写IO模块缓冲区的数据，再继续执行。这一轮询过程中CPU是始终在没有意义地忙的，因为轮询的实质是“等待完成”，表现在程序执行上就是*阻塞*。偏偏IO设备的速度往往远低于CPU，故轮询会造成巨大的CPU资源浪费。

例如：

> 常见家用机械硬盘是7200转/s的，故磁碟旋转半周需要4ms，耗时约400万CPU周期，若不使用中断，读取硬盘数据的过程中，CPU不得不等待机械硬盘寻道读取数据再写入到缓冲区，CPU才能读取，这是巨大的浪费。

中断机制允许采用如下机制：CPU向硬盘控制器发出读信号后，不作轮询，继续执行接下来的程序。硬盘控制器在完成读盘后，触发CPU中断，CPU暂停当前指令流，执行中断处理程序读入硬盘缓冲区里的数据，最后恢复指令流继续执行。

一个合适的类比是**回调**。中断机制可以看作允许CPU为IO操作注册“回调”。（实质上回调机制最有效的应用场景之一正是基于硬件中断的IO复用）

常见的中断类型：
- 程序中断：也称“异常”，即程序执行了不合法的操作
- 硬件故障中断
- **IO中断**：由IO控制器产生，用以通知CPU完成了某IO操作。举例：磁盘读写，网络通信，打印
- **时钟中断**：CPU内部计时器产生，用来实现“定时类”功能。

中断机制的一个很好的案例是Nginx的异步IO复用。（待完善）

### Process
- Process Image = Code Segment + Data Segment + Stack Segment + Process Control Block(PCB)
- PCB
  - pid（可能还有ppid,uid）
  - state: running/ready/blocked
  - priority
  - Program Counter (PC)
  - memory pointers: 内存相关指针
  - context: registers
  - IO information: such as file descriptors
  - accounting information: 进程相关统计信息
  - 注意，PCB中memorgy pointers + context + IO info.对应管理的资源可以看作一台逻辑上完整的计算机的全部资源。这暗示了进程运行相互独立相互隔离的特点
- 进程状态模型
  - 二状态模型
    - 最基本的模型，进程分别为运行态和等待态
    - 过于简单
  - 五状态模型
    - 进程分为*运行态*、*就绪态*和*阻塞态*，以及方便管理的起始态和结束态
    - *运行态*表示进程正在运行
    - *就绪态*表示进程不在运行，但请求的资源都已就绪，只等调度器调入运行
    - *阻塞态*表示进程正在等待IO/其他资源，从而阻塞
  - 六状态模型/七状态模型
    - 结合虚拟存储器，可以在无状态模型上添加*挂起态*
    - 挂起态的进程不在运行，且进程映像被调出主存，存在辅存中
    - 设计挂起态的动机是解决主存容量不足，将长久不运行的进程移出主存，在需要的时候才调入
    - 不正确地使用挂起态可能会导致性能下降（缺页的时间代价很大）
    - 由于虚拟存储器地分页机制，不一定要把整个进程映像挪到辅存中，可以把一部分（部分页）放在辅存中
- 进程控制原语
  - 依赖OS的*原语*来实现进程的分发、状态切换等操作
  - 原语与常规程序偏度不同，原语是*原子操作*，不可以中断，否则会导致混乱
  - 一个常见的手法是通过不响应中断来实现原子性
  - 逻辑上来看，OS原语可以看作对ISA的扩充，增加了指令

### Process vs. Thread
- 进程是**资源分配的最小单位**
  - OS为进程分配pid、内存、fd表等资源，*不单独为线程分配这些资源*
  - 具有独立的PCB、特权级等
  - 进程可以是OS层面并发执行的较粗粒度。
- 线程是**调度执行的最小单位**
  - OS可以以线程为单位分配CPU时间。
  - 线程是OS层面并发执行的最小粒度。
  - 同一进程派生的多个线程**共享资源**，比如fd，内存地址空间等

### 用户级线程 vs. 内核级线程

用户级线程（ULT）
- 在用户级代码实现多线程
- 代表性的库是pthread
- 优点：
  - 不需要切换至内核态
  - 调度策略可以由应用程序定制
  - 可以跨平台
- 缺点：
  - 由于发起系统调用时进程被阻塞，只要有一个线程发起系统调用时，同一进程的所有派生的用户级线程都会阻塞
  - 在纯粹的用户级线程策略中，用户级线程无法利用多核
- 当然现在的ULT解决了部分缺点，比如说非阻塞的系统调用
  
系统级线程（KLT）
- 线程管理由内核完成，OS的调度以线程为单位
- 优点：
  - 线程阻塞不会导致进程阻塞
  - 充分发挥多核优势
- 缺点：
  - 线程调度切换需要内核介入，故有模式切换开销

还有混合ULT和KLT的方案（比如Solaris），在线程创建在用户态，线程调度和同步在内核态，此时ULT被映射到了若干个KLT

### 对称多处理SMP：同构

SMP 对称多处理是指**有多个具有相同功能的逻辑上的处理器**， 也即*同构*多处理器技术（区别异构）

多核处理器是SMP的一种实现，又称为*片上SMP*

### Windows进程模型

Windows系统思想：**一切皆资源/一切皆对象**。所有的资源都表示为对象(object)，然后使用句柄(handle)来管理。进程是占用资源的基本单位，一个进程的句柄表包含该进程拥有的资源，比如打开的文件、代码段、数据段，和*线程对象*。（由此可见，Windows下进程和线程是截然不同的逻辑实体）

Windows对象具有*属性*和*服务*（方法），许多时候，Windows的进程/线程属性对标的就是进程模型的PCB/TCB

### Linux进程模型
Linux的设计思想：**一切皆文件**。因此Linux进程占有的资源主要表现为其“打开”的文件，或者说其*文件描述符表*

Linux实际上没有区分进程和线程

### Mac/iOS的GCD技术
Mac/iOS处理基本的内核即线程实现之外，还在OS中提供了更强大的自动线程管理功能。用户不需要显式使用OS API，而是使用拓展的C语言记号来标识需要并发的“块”，然后由OS来创建线程、管理线程，根据底层硬件的特性来调整策略。

### 互斥：六个要求
- **强制排他**：这是最基本的要求。同一时刻只有一个进程进入临界区
- **让权等待**：当进程无法进入临界区时立刻释放处理器，防止**忙等待**（浪费CPU时间）
- **有限等待**：一个试图进入临界区的进程不会无限地等待，也即不会*饥饿*
- **充分并发**：各个进程可以互不干扰地并发运行
- 满足异步：各个进程并发逻辑不受处理器数量和相对速度影响
- 空闲让进：当没有代码试图进入临界区时，一个进入临界区的尝试可以立刻成功


### 互斥：软件实现：Dekker算法
考虑多线程互斥，使用全局变量flag来表示n个竞争进入临界区的线程。使用turn表示“是否谦让”。大致流程如下：
1. `flag[id]`标为true
2. 轮询其他所有flag
3. 若互斥，等待，若谦让，在短暂`flag[id]=false`后重新使`flag[id]=true`
4. 进入临界区
5. `flag[id]`标为false

问题：
- 逻辑复杂，难以证明
- 轮流问题（谦让度顺序变化）
- **忙等待**

### 互斥：软件实现：Peterson算法

考虑多线程互斥，大致流程
1. `flag[id]=1`
2. `turn=other's id`
3. 轮询其他所有flag，检查turn，只要当有其他人flag为真且turn不等于自己时就等待
4. 进入临界区
5. `flag[id]=0`

特点：
- 较容易实现
- 无轮流
- **忙等待**

### 互斥：硬件实现

简单粗暴：关中断
- 在进程进入临界区的时候关中断（不响应中断）
- 缺点1：限制了处理器交替执行的能力
- 缺点2：对多核情形不生效（单核情形下一切切换源自中断，但多核情形下具有天然的并行）

完整实现：**TS/XCHG&自旋锁**

- 观察软件方案，可以发现软件方案失败的根本原因是**轮询操作中“test”和“set”操作中间可能被切换**。因此可以在硬件上设计一个“TestSet”指令在一个指令周期内完成两个操作
- 此方案适用如下情形：
  
  互斥的存储器 & 共享存储的SMP

- TestSet实现自旋锁
  考虑如下自旋锁的（伪）汇编代码：
  ```asm
  lockvar db 0

  proc lock(lockvar)
    loop:
      TS lockvar
      jnz loop
    ret
  endproc

  proc unlock(lockvar)
    loop:
      mov lockvar, 0
    ret
  endproc
  ```

  代码说明：

  加锁逻辑：lockvar为0时没有进程在临界区中，1则表示有进程在临界区中。测试lockvar的值并将lockvar置1，若lockvar的原来的值是0，则成功获得锁，允许进入临界区；否则，获得锁失败，循环等待，直到lockvar为0。

  关键点：
  - 硬件实现了一个TS指令，**在一个指令周期**内完成“检查lockvar的值”和“lockvar置1”的动作。由于在一个指令周期内，**两个动作是不会被中断**，且由于存储器的“互斥”，**多个处理器同时加锁也只有一个进程获得锁**
  - 无论测试结果如何，都要置1的理由是：若加锁失败，lockvar肯定本来就是1，不受影响；若加锁成功，为了排除其他进程，也必须立即将lockvar设为1
  
- XCHG实现自旋锁
  
  XCHG可以在一个指令周期内**交换一个寄存器和一个内存单元的数据**

  ```asm
  lockvar db 0

  proc lock(lockvar)
    loop: 
      mov ax, 1
      XCHG ax, lockvar
      jnz loop
    ret
  endproc

  proc unlock(lockvar)
    mov ax, 0
    ret
  endproc
  ```

  可以看到，XCHG和TS指令工作的实质是一样的：在一个指令周期内同时获知一个内存单元的值并设置该内存单元的值。XCHG将内存单元的值和寄存器的值对调，然后测试寄存器的值即可知道内存单元原来的值。

- 自旋锁 vs 互斥锁
  - 互斥锁是*sleep-waiting*（让权等待），等待锁的进程会阻塞，在解锁之前阻塞不会获得CPU时间
  - 自旋锁是*busy-waiting*（忙等待），等待锁的进程不会阻塞，而是不断轮询（不断循环）。由于没有阻塞，该进程会占用CPU时间
  - 自旋锁：
    - 由于不阻塞，如果等待时间很短，性能会远胜于互斥锁
    - 易于实现
    - 如果等待时间很长，由于忙等待，将浪费CPU时间
    - 可能饥饿
    - 可能死锁
  - 互斥锁：
    - 由于等待的时候阻塞，然后又唤醒调入，开销较大
    - 但由于等待的时候阻塞（让权等待），不会浪费CPU时间
    - 由于可以由OS调度，可以减少饥饿的问题
    - 可能死锁

### 信号量

信号量其实就是就是进程间通信用的一个共享的整数变量。

一个信号量只有三种合法操作

1. 初始化
   
   初始化信号量为一个非负整数。具体取值取决于使用信号量的具体情景。

2. P操作（Wait/Down）
   
   信号量减1。若信号量此时**为负**，**执行P操作的进程阻塞**
  
3. V操作（Signal/Up）
   
   信号量加1。若信号量此时**非正**，**唤醒其中一个因P操作阻塞的进程**。

注意，每一个信号量对应一个阻塞队列，其中放置了由于对该信号量的P操作阻塞的所有进程。

信号量除了是一个整数，还需要对应一个*阻塞队列*，存放**因对该信号量做P操作而阻塞的进程控制块**

一种取值只能是0或者1的特殊的信号量，称为*二元信号量*。由于此时这种信号量不存在负数的情形，因此二元信号量不是根据信号量取值来判断是否阻塞的，而是检测*阻塞队列是否为空*。因此，所谓二元信号量其实跟那个整数没什么关系。

#### 信号量实现

可以发现，对同一个信号量的P操作V操作是典型的可能导致竞态的操作。因此，P/V操作必须利用自旋锁来确保互斥修改（不要试图用互斥锁，因为互斥锁本事就是用信号量实现的。。。）


#### 信号量实现互斥锁

显然，如果信号量初始为1，该信号量其实就是sleep-waiting的**互斥锁**（由于是sleep-waiting，所以不是自旋锁）

几个要点：
1. 配置一个**初始为1**的信号量（常常被称为*互斥量*）
2. 试图进入临界区的进程需要对信号量执行P操作（即*lock*）
3. 离开临界区时，进程对信号量执行V操作（即*unlock*）

#### 生产者-消费者问题

问题描述：

若干个进程通过有限的共享缓冲区交换数据
- 一组“生产者”进程不断写入
- 另一组“消费者”进程不断读出
- **任何时刻只能有一个进程可以对缓冲区进行操作**

解决方案：**使用信号量实现的队列**。
- 使用一个信号量用于同步。
- 生产者每次将产品入队都会导致信号量+1；
- 当队列为空的时候，试图获取产品的消费者将会导致信号量为负，从而导致消费者阻塞等待；
- 生产者一放入新产品，就会导致信号量+1，若信号量为负，等待的某个消费者进程立即被唤醒，并得到新入队的产品，继续执行。
- *若缓冲区有限，则在缓冲区满的情况下，生产者可能需要阻塞等待。此时可能需要增加一个信号量。
- 最后，由于涉及共享变量的修改，所以还需要一个互斥锁

#### 读者-写者问题

问题描述：对于同一组数据资源（比如文件），要求满足以下要求：
- 任意多个读进程可以同时读文件
- 一次只能有一个写进程写文件
- 如果一个写进程在写文件，任意读进程都不能读文件

这种问题的典型情境是*数据库的读写*。数据库90%的请求都是读，数据库需要满足大量并发的读请求，因此要允许大量进程同时读；但又需要维护数据一致性，因此必须在写的时候锁定数据表。

容易既有读者在排队，又有写者在排队，因此有两种策略：
1. 读者优先：当读者持有锁的时候，任何新的读者都可以立刻进入使用资源
2. 写者优先：当读者持有锁，写者在等待时，新来的读者不能立刻进入使用资源，而是现有读者使用完之后立刻将资源交给写者。

读者有限的解决方案如下：
1. 初始化信号量`r=1,w=1`
2. 读者逻辑：
   
   1. `p(r)`
   2. 当前读者数+1
   3. 若当前读者数=1，则`p(w)`
   4. `v(r)`
   5. `READ`操作
   6. `p(r)`
   7. 当前读者数-1
   8. 若当前读者数=0，则`v(w)`
   9. `v(r)`

3. 写者逻辑：

   1. `p(w)`
   2. `WRITE`操作
   3. `v(w)`

注：
- 写者逻辑非常简单：每次写数据之前`lock(w)`，写完`unlock(w)`
- 读者需要使用两个锁：
  - 当前读者数量是所有读者线程共享的变量，修改时都要`lock(r)`
  - 若一个新的读者获得读锁，发现`reader_count==1`，说明**在它之前，读者并未对资源加锁**，此时必须执行`lock(w)`来保证不会既读又写。
  - 若一个新读者获得读锁，发现`reader_count>1`，说明**在它之前，读者已经为资源加锁了，其他读者可以自由进入资源临界区读数据**
  - 无论何种情况，一个新读者完成`lock(r)`并互斥地为读者数量+1之后，可以`unlock(r)`了
  - 类似的，当读取完成，`reader_count--`时，若`reader_count==0`，就要`unlock(w)`了
- **读者优先可能导致写者饥饿**。由于当读者持有锁的时候，任何新的读者都可以立刻进入使用资源，也即若不断有新的读者进入，写者永远无法进入临界区。因此实际操作中写者优先相对读者优先实用。

写者优先的解决方案如下：

```
writer:
  p(y)
  write_count++
  if (write_count==1) p(rsem) 
  v(y)

  p(wsem)
  WRITE_UNIT()
  v(wsem)

  p(y)
  write_count--
  if (write_count==0) v(rsem)
  v(y)
```

```
reader:
  p(z)
  p(rsem)

  p(x)
  read_count++
  if (read_count==1) p(wsem)
  v(x)

  v(z)
  READ_UNIT()

  p(x)
  read_count--
  if (read_count==0) v(wsem)
  v(x)
```

#### 进程同步

互斥可以*强制排他*，结果上来说可以实现**临界区访问的顺序化**（无重叠），但它无法保证多个协作进程的**时序**。并发进程之间的时序约束问题称为*进程同步*问题。

#### 信号量实现进程同步

考虑`a -> b`的一个同步要求，采用一个信号量实现`s`

要点如下：
1. 初始化`s=0`
2. a完成后执行`v(s)`操作
3. b开始前执行`p(s)`操作（即*join*）

### 消息机制

一种相对高层的IPC机制

两种原语：

- `send` 发送消息
- `receive` 接收消息
  
其中`send/receive`都可以是阻塞/非阻塞的

消息传递既可以是直接发送给给定PID的进程，也可以是使用中间代理结构（信箱）来通信

作为一种高级的IPC方式，消息机制完全可以用于*分布式系统*。

实现消息机制最重要的部件是*消息队列*

### 死锁

死锁发生的四个必要条件

1. 互斥
   
   进程可以排他地占有资源

2. 占有等待
   
   进程在由于请求其他资源阻塞等待的时候仍然占有着属于自己的资源

3. 不可抢占
   
   不允许一个进程*抢占*另一个进程的资源。

   *抢占*是指某资源在其持有的进程使用完并主动释放之前被另一个资源强占。

作为前三个条件的结果，条件四：

4. 循环等待
   


总体上，三种解决死锁的策略：

1. 死锁预防
   
   保守的策略，通过**破坏死锁发生的必要条件**来完全杜绝死锁的发生。

2. 死锁避免

   类似死锁预防

3. 死锁检测
   
   在运行时由OS定期扫描检测死锁

#### 死锁预防

1. 破坏互斥：不可能
   
   互斥是并发程序避免RC保持数据一致性的基础，不可能通过这一方法来避免死锁。

2. 破坏占有等待：**初始一次性申请所有资源**
   
   若要求进程在创建之时申请所有需要的资源，得到资源之后才允许启动，**不允许进程在执行过程中申请新的资源，则可以避免占有着资源进行阻塞等待**。

   优点：易于实现、易于理解

   缺点：
   - 资源利用率低：进程在运行的整个生命周期中占有着所有涉及到的资源，但该资源可能只是在进程执行的一小部分使用到了该资源，剩余时间资源都空置浪费了。

3. 抢占
   
4. 破坏循环等待：按序分配
   
   含义：进程A若想申请资源$R_j$，必须保证$\forall i < j$，资源$R_i$已被分配。若条件不满足，必须按需地申请所有前面的资源$R_i$，即便不需要该条件

   实际上这一方法只适用于一个小的资源集合上。
  
#### 死锁避免

死锁预防：通过**制定静态的资源管理策略，破坏死锁发生的条件，从原理上杜绝死锁的发生**。这些策略都是静态、保守的，且往往**极大地影响进程的并发执行效率/并发的灵活度**。

死锁避免：在不试图破坏死锁发生的必要条件的情况下，通过**适当设计资源动态分配策略，避免循环等待**

对比定义发现，死锁预防和死锁避免其实都是试图从原理上杜绝死锁地发生，但死锁避免更灵活，限制相对少。

一个典型的死锁避免策略是*银行家算法*

应用银行家算法有如下前提：
1. 可以使用一个整数描述一个资源类的资源实例数目
2. 资源都是可重用资源
3. **每个进程需要的每类资源的最大数量都是在进程创建时预先声明的**

使用如下符号：
- $m,n$表示$m$个进程，$n$个资源类
- $R \in \mathbb{R}^n$表示系统拥有的各类资源的总数
- $C,A \in \mathbb{R}^{m\times n}$分别表示每个进程声明的需要的最大资源数目以及每个进程目前分配得到的每类资源的数目
- $V \in\mathbb{R}^n$表示各类资源当前可用的数目
- 一组$(R,C,A,V)$表示一个系统资源的状态。显然，该表示其实是冗余的.（$V_j \equiv R_j - \sum_{i=1}^{m} A_{ij}$）

- **进程启动拒绝**

  显然，当新进程$m+1$满足：
  $$
    C_{m+1, j} + \sum_{i=1}^{m} C_{ij} \le R_j
  $$

  时，进程才能启动。

  这一策略是保守的，不是最优的，因为它考虑的是最坏情况：所有进程同时请求所有资源的最大数目。实际上这种情况并不一定会发生（甚至不可能发生）

- **资源分配拒绝（银行家算法）**：
  
  当**存在**$i$使得
  $$
    C_{ij} - A_{ij} \le V_{j}
  $$

  时称状态$(R,C,A,V)$为*安全状态*。不满足上述条件（不存在符合条件的$i$），称为*不安全状态*

  安全状态的意义在于**安全状态下的系统保证至少存在一条资源分配路径使得当前所有并发进程运行至结束**

  反之，依据安全状态的充分条件，我们可以通过计算确定一个资源分配请求是否会导致不安全状态，从而**拒绝一个导致不安全状态的资源请求**

银行家算法的优点：
- 更灵活，支持资源的动态分配
- 不需要抢占、回滚
- 减少潜在的死锁问题

银行家算法的缺点：
- 无法处理所有形式的资源
  - 无法处理不可重用资源
  - 无法处理难以量化的系统资源
- 不支持系统动态扩容
  - 系统的资源类的数目固定
  - 系统的各个资源类的资源实例数目固定
- 没有考虑进程同步问题
- 系统性能影响：可能会阻塞合理的资源分配请求
- 不够灵活：需要预先声明进程需要的最大资源数目
- 算法性能问题：不考虑硬件加速，每一次检查状态是否安全都需要$O(mn)$的时间

可以发现，即便银行家算法有许多优点，其缺陷仍然是不可接受的，因此在实践中OS都没有采用银行家算法。

#### 死锁检测

相比于死锁预防和死锁避免，死锁检测不试图通过限制资源的分配来避免死锁，而是在死锁发生之后检测出死锁并恢复系统。

检测的策略一般是：资源分配时检查+周期性检查

检测出死锁后恢复系统的方法：
1. 杀死进程直至死锁解开（常见，简单粗暴）
2. 回滚进程

#### 综合的死锁处理策略

实际上，计算机资源的特点各不相同，适合的死锁处理技术也各不相同。现在，OS采用的是针对不同的资源类采用不同的死锁处理策略。

#### 哲学家就餐问题

问题：考虑五个哲学家做围桌，每两个座位之间都有一把叉子（共5把），作为结果，每个作为左右都有一把叉子。每个人必须要两把叉子才能吃，问如何避免死锁和饥饿。

这个问题的特点在于**资源图的环已经天然存在，若使用朴素的互斥方案，一定会导致循环等待造成死锁，且这一死锁会导致所有人饥饿**（字面，笑）

朴素的解决方案（会导致全部死锁饥饿）：
```
semaphore fork[5] = {1, 1, 1, 1, 1}
philosopher:
  P(fork[left])
  P(fork[right])
  eat()
  V(fork[right])
  V(fork[left])
```

一种简单的解决方案是只允许至多4个哲学家同时就餐：
```
semaphore fork[5]
semaphore room = 4
philosopher:
  P(room)
  P(fork[left])
  P(fork[right])
  eat()
  V(fork[right])
  V(fork[left])
  V(room)
```

由于只有4个人同时就餐的时候资源图不构成环，因此不会死锁。问题是不完全符合问题的场景：命名是5个人的餐桌

另一种方法是利用管程（条件变量）：
```
cv fork[5]
get_fork():
  if fork[left]:
    fork[left] = false
  else:
    cwait(fork[left])
  if fork[right]:
    fork[right] = false
  else:
    cwait(fork[right])
  
release_fork():
  fork[right] = true
  csignal(fork[right])
  fork[left] = true
  csignal(fork[left])

philosopher:
  get_fork()

  eat()

  release_fork()
```

可以发现，相比朴素方案，这种方案除了将信号量换成了条件变量，其他完全一致。但不会死锁。因为**同时只有一个进程能进入管程**，从结果来看，这种互斥结构导致**get_fork/release_fork逻辑上成为了原子操作**

## 存储管理管理
- 覆盖技术
  
  较老的技术。由程序员描述模块的依赖关系（表示为树状），内存只需要放置当前运行的进程的依赖路径上的模块，余下的放入辅存中，从而节省内存。

- 交换技术
  
  古老的整体交换技术在进程不运行的时候由OS自动将程序调到硬盘上。相比覆盖技术，这种技术的好处在于对用户是透明的。

- 分页管理
  - 起点：固定分区管理（partition）
    
    将线性内存分成等大的若干*分区*，每个占用内存小于分区的进程可以将整个分区分配给进程，然后直接载入。

    优点：简单，内存不够就用整个分区做交换。
    缺点：
    1. 进程占用内存大于一个分区则需要多个分区，无法整体交换，又回到覆盖算法
    2. 进程小于分区大小，空余的空间无法利用，造成内存的*内碎片(internal fragment)*
    3. 预先划分的分区数目实际上限制了最大并发活动进程数目
   
  - 动态分区：
    
    优点：灵活，内存利用率高，消除了内碎片
    缺点：导致外碎片（内存切割出来的中间的小空隙）

    动态分区放置算法：
    - 首次适配
      
      从内存起始开始扫描，找到第一个适配的分区。

      简单，通常效果是最好的。

    - 临近适配
      
      从上次分配结束的地方开始扫描，找到一个适配的分区。

      需要经常压缩。

    - 最佳适配
      
      扫描整个内存，找到最小的适配（足够用）的分区

      其实是最坏，产生碎片最多。

    - 最坏适配
      
      扫描整个内存，找到最大的内存块来分配分区
  
- 页式存储管理
  - 基本原理：
    - 将主存划分为若干等长小块，称为*页框(frame)*
    - 将进程分为若干个*页(page)*，一个页的大小与一个页框大小相同
    - 进程加载时，所有页都放入了某个可用的页框（不要求连续）。
    - 建立页表，管理所有的页和页框
    - 所谓的页是“逻辑上的”，“虚拟的”，存在于虚拟地址中，虚拟页的号码称为虚页号。所谓页框就是物理页，页框号也称为实页号。
    - **页式存储管理的核心为利用页表将虚页号号转换为实页号，将虚拟地址转换为线性地址（物理地址）**
    - 相比段式存储管理，页式存储管理**对高层用户是透明的**
  - 优点：
    - 几乎可以认为消除了内存碎片
  - 缺点：
    - 不易共享和保护
    - 不易动态链接
    - 不易处理数据结构的扩容

- 段式 vs 页式
  1. **分页机制是对用户透明的，分段对用户可见**；
  2. 页大小固定（通常是4K），段长是可变的；
  3. **分页的目的是实现虚拟内存，分段的目的是便于模块化、管理**；
  4. 分页的地址空间是一维的，分段的地址空间是二维的
  5. **启用分页的以后逻辑地址上的连续不意味着物理地址**，分段保持地址空间的连续性
  6. 分页不便于共享，分段便于共享
  7. 分页是保护模式下的可选特性，分段是保护模式特权级实现的基础，是必须使用的特性
  8. 分页的地址变换更灵活，但**段内逻辑地址不小于段基址**
  9. 分页可以消除内存碎片，分段造成内存碎片
  
## 虚拟存储器
基本特点：
1. 不连续性
2. **部分交换**
3. 大空间
  
虚拟内存的实现依赖硬件和软件支持：
- 硬件支持：分页、页表需要硬件处理才能有可以接受的性能
- 软件支持：页面替换的策略。

虚拟分页：

利用页式存储管理，**只将部分页面放入内存**

### 反向页表

针对64位计算机过于庞大的逻辑地址空间，采用*反向页表*取代多级页表方案。

反向页表：**使用物理页号作为索引，虚页号放在页表内**，然后**搜索表，找到匹配项，匹配的表项的索引号就是需要的物理页号**